

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/dajiangdahe/img/favicon.png">
  <link rel="icon" href="/dajiangdahe/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="Hello,here is kengkeng&#39;s blog.">
  <meta name="author" content="kengkeng">
  <meta name="keywords" content="">
  
  <title>Kafka从入门到放弃 - kengkeng&#39;s life</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/dajiangdahe/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/dajiangdahe/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"kengkengya.github.io","root":"/dajiangdahe/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":1},"lazyload":{"enable":false,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/dajiangdahe/js/utils.js" ></script>
  <script  src="/dajiangdahe/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/dajiangdahe/">&nbsp;<strong>kengkeng's life</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/dajiangdahe/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/dajiangdahe/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/dajiangdahe/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/dajiangdahe/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/dajiangdahe/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/dajiangdahe/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Kafka从入门到放弃">
              
            </span>

            
              <div class="mt-3">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-author" aria-hidden="true"></i>
      kengkeng
    </span>
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-01-04 18:51" pubdate>
        2022年1月4日 晚上
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      10.5k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      120
       分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Kafka从入门到放弃</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：3 个月前
                
              </p>
            
            <div class="markdown-body">
              <h1>第 1章 Kafka 概述</h1>
<h2 id="1-1-定义">1.1 定义</h2>
<p><code>Kafka</code> 是一个分布式的基于发布/订阅模式的消息队列（<code>Message Queue</code>），主要应用于大数据实时处理领域。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png-20220105165020501.png" class="" title="img">
<p>一个典型的Kafka体系架构包括若干Producer（可以是服务器日志，业务数据，页面前端产生的page view等等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer (Group)，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。Producer使用push(推)模式将消息发布到broker，Consumer使用pull(拉)模式从broker订阅并消费消息。</p>
<h2 id="1-2-消息队列">1.2 消息队列</h2>
<h3 id="1-2-1-传统消息队列的应用场景">1.2.1 传统消息队列的应用场景</h3>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220104190400222.png" class="" title="image-20220104190400222"> 
<p><strong>使用消息队列的好处</strong></p>
<p>1） 解耦</p>
<p>允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p>
<p>2） 可恢复性</p>
<p>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p>
<p>3） 缓冲</p>
<p>有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致 的情况。</p>
<p>4）灵活性   &amp;  峰值处理能力</p>
<p>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。 如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列 能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p>
<p>5）异步通信</p>
<p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户 把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要 的时候再去处理它们。</p>
<h3 id="1-2-2-消息队列的两种模式">1.2.2  消息队列的两种模式</h3>
<p><strong>（1）点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）</strong></p>
<p>消息生产者生产消息发送到 <code>Queue</code> 中，然后消息消费者从 <code>Queue</code> 中取出并且消费消息。 消息被消费以后，<code>queue</code> 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。 <code>Queue</code> 支 持 存 在 多 个 消 费 者 ， 但 是 对 一 个 消 息 而 言 ， 只 会 有 一 个 消 费 者 可 以 消 费 。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220104190607741.png" class="" title="image-20220104190607741">
<p><strong>（2）发布/订阅模式（一对多，消费者消费数据之后不会清除消息）</strong><br>
消息生产者（发布）将消息发布到  <code>topic</code> 中，同时有多个消息消费者（订阅）消费该消 息。和点对点方式不同，发布到  <code>topic</code> 的消息会被所有订阅者消费。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220104190623124.png" class="" title="image-20220104190623124">
<h2 id="1-3-Kafka-基础架构">1.3 Kafka 基础架构</h2>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220104190748143.png" class="" title="image-20220104190748143">
<p>1）<strong><code>Producer</code></strong>  ：消息生产者，就是向  <code>kafka broker</code> 发消息的客户端；</p>
<p>2）<strong><code>Consumer</code></strong>  ：消息消费者，向  <code>kafka broker </code>取消息的客户端；</p>
<p>3）<code>**Consumer Group  （CG）**</code>：消费者组，由多个 <code>consumer</code> 组成。消费者组内每个消费者负 责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所 有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>
<p>4）<strong><code>Broker</code></strong>  ：一台 <code>kafka</code> 服务器就是一个 <code>broker</code>。一个集群由多个 <code>broker</code> 组成。一个 <code>broker</code>可以容纳多个 <code>topic</code>。</p>
<p>5）<strong><code>Topic</code></strong>  ：可以理解为一个队列，生产者和消费者面向的都是一个  <code>topic</code>；</p>
<p>6）<strong><code>Partition</code></strong>：为了实现扩展性，一个非常大的 <code>topic</code> 可以分布到多个 <code>broker</code>（即服务器）上，一个 <code>topic</code> 可以分为多个  <code>partition</code>，每个 <code>partition</code> 是一个有序的队列；</p>
<p>7）<strong><code>Replica</code></strong>：副本，为保证集群中的某个节点发生故障时，该节点上的 <code>partition</code> 数据不丢失，且 <code>kafka</code> 仍然能够继续工作，<code>kafka</code> 提供了副本机制，一个 <code>topic</code> 的每个分区都有若干个副本， 一个 <code>leader</code> 和若干个 <code>follower</code>。</p>
<p>8）<strong><code>leader</code></strong>：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 <code>leader</code>。</p>
<p>9）<strong><code>follower</code></strong>：每个分区多个副本中的“从”，实时从 <code>leader</code> 中同步数据，保持和 <code>leader</code> 数据的同步。<code>leader</code> 发生故障时，某个  follower 会成为新的  <code>follower</code>。</p>
<h1>第  2 章    Kafka 快速入门</h1>
<h2 id="2-1-安装部署">2.1 安装部署</h2>
<p><a href="https://kengkengya.github.io/dajiangdahe/2022/01/03/zookeeper_kafka_kafka-Manager%E5%8D%95%E6%9C%BA%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/">Zookeeper_kafka_kafka-Manager单机伪集群环境安装</a></p>
<h2 id="2-2-Kafka-命令行操作">2.2 Kafka 命令行操作</h2>
<ol>
<li>
<p>查看当前服务器里所有的<code>topics</code>:</p>
<figure class="highlight shell"><figcaption><span>l</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">/opt/kafka_2.13-2.8.1 # bin/kafka-topics.sh   --zookeeper 10.121.17.138:2181 --list<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>创建<code>tpoic</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">/opt/kafka_2.13-2.8.1 # bin/kafka-topics.sh --create  --zookeeper 10.121.17.138:2181 --topic first --partitions 2 --replication-factor 2<br>Created topic first.<br></code></pre></td></tr></table></figure>
</li>
</ol>
<p>​		选项说明：<br>
​				<code>	--topic</code>  定义 <code>topic</code> 名</p>
<p>​			<code>--replication-factor</code>    定义副本数</p>
<p><code>			--partitions </code>   定义分区数</p>
<ol start="3">
<li>
<p>删除<code>topic</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">/opt/kafka_2.13-2.8.1 # bin/kafka-topics.sh --delete  --zookeeper 10.121.17.138:2181 --topic first<br>Topic first is marked for deletion.<br>Note: This will have no impact if delete.topic.enable is not set to true.<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>查看<code>topic</code>详细信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">/opt/kafka_2.13-2.8.1 # bin/kafka-topics.sh --describe  --zookeeper 10.121.17.138:2181 --topic first<br><br>Topic: first	TopicId: h7I5zqd-R7Sj3hd-P7q1gQ	PartitionCount: 2	ReplicationFactor: 2	Configs:<br>	Topic: first	Partition: 0	Leader: 1	Replicas: 0,1	Isr: 1,0<br>	Topic: first	Partition: 1	Leader: 2	Replicas: 1,2	Isr: 2,1<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>发送消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">bin/kafka-console-producer.sh --broker-list 10.121.17.138:9092 --topic first<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>消费消息（必须先开启消息，再启动生产者）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">bin/kafka-console-consumer.sh  --zookeeper 10.121.17.138:2181 --topic first --from-beginning<br></code></pre></td></tr></table></figure>
<p><code>--from-beginning</code>：会把主题中以往所有的数据都读取出来</p>
</li>
<li>
<p>修改分区数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">bin/kafka-topics.sh   --zookeeper 10.121.17.138:2181 --alter --topic first --partitions 6<br></code></pre></td></tr></table></figure>
</li>
</ol>
<h1>第  3 章    Kafka 架构深入</h1>
<h2 id="3-1-Kafka-工作流程及文件存储机制">3.1 Kafka 工作流程及文件存储机制</h2>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220105154350679.png" class="" title="image-20220105154350679">
<p><code>Kafka</code> 中消息是以  <code>topic</code> 进行分类的，生产者生产消息，消费者消费消息，都是面向  <code>topic</code> 的。</p>
<p><code>topic</code> 是逻辑上的概念，而 <code>partition</code> 是物理上的概念，<strong>每个 <code>partition</code> 对应于一个 <code>log</code> 文 件，该 <code>log</code> 文件中存储的就是 <code>producer</code> 生产的数据</strong>。<code>Producer</code> 生产的数据会被不断追加到该 log 文件末端，且每条数据都有自己的 <code>offset</code>。消费者组中的每个消费者，都会实时记录自己 消费到了哪个 <code>offset</code>，以便出错恢复时，从上次的位置继续消费。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220105155713384.png" class="" title="image-20220105155713384">
<p>由于生产者生产的消息会不断追加到 <code>log</code> 文件末尾，为防止 <code>log</code> 文件过大导致数据定位 效率低下，<strong>Kafka 采取了分片和索引机制</strong>，将每个 <code>partition</code> 分为多个 <code>segment</code>。每个 segment 对应两个文件——“<code>.index</code>”文件和“<code>.log</code>”文件。这些文件位于一个文件夹下，该文件夹的命名 规则为：<code>topic</code> 名称+分区序号。例如，first 这个 topic 有三个分区，则其对应的文件夹为<code> first- 0,first-1,first-2</code>。</p>
<figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-number">00000000000000000000</span>.<span class="hljs-built_in">index</span><br><span class="hljs-number">00000000000000000000</span>.<span class="hljs-built_in">log</span><br><span class="hljs-number">00000000000000170410</span>.<span class="hljs-built_in">index</span><br><span class="hljs-number">00000000000000170410</span>.<span class="hljs-built_in">log</span><br><span class="hljs-number">00000000000000239430</span>.<span class="hljs-built_in">index</span><br><span class="hljs-number">00000000000000239430</span>.<span class="hljs-built_in">log</span><br></code></pre></td></tr></table></figure>
<p><code>index</code> 和  <code>log</code> 文件以当前  <code>segment</code> 的第一条消息的  <code>offset</code> 命名。下图为  <code>index</code> 文件和  <code>log</code> 文件的结构示意图。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220105160059914.png" class="" title="image-20220105160059914">
<p>首先在<code>index</code>文件根据二分查找法查找索引（每一个offset都是一样大），找到<code>offset=3</code>的起始值。然后今后<code>log</code>文件进行查找。<code>**.index</code>文件存储大量的索引信息，<code>.log</code>文件存储大量的数据**，索引文件中的元数据指向对应数据文件中 <code>message</code> 的物理偏移地址。</p>
<h3 id="3-1-1-复制原理和同步方式">3.1.1 复制原理和同步方式</h3>
<p><code>Kafka</code>中<code>topic</code>的每个<code>partition</code>有一个预写式的日志文件，虽然<code>partition</code>可以继续细分为若干个<code>segment</code>文件，但是对于上层应用来说可以将<code>partition</code>看成最小的存储单元（一个有多个<code>segment</code>文件拼接的“巨型”文件），每个<code>partition</code>都由一些列有序的、不可变的消息组成，这些消息被连续的追加到<code>partition</code>中。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png.png" class="" title="这里写图片描述">
<p>上图中有两个新名词：<code>HW</code>和<code>LEO</code>。这里先介绍下<code>LEO</code>，<code>LogEndOffset``的缩写，表示每个</code>partition<code>的</code>log<code>最后一条</code>Message<code>的位置。</code>HW<code>HighWatermark</code>的缩写，是指<code>consumer</code>能够看到的此<code>partition</code>的位置，这个涉及到多副本的概念，这里先提及一下，下节再详表。</p>
<p>言归正传，为了提高消息的可靠性，<code>Kafka</code>每个<code>topic</code>的<code>partition</code>有N个副本（<code>replicas</code>），其中N(大于等于1)是<code>topic</code>的复制因子（<code>replica fator</code>）的个数。<code>Kafka</code>通过多副本机制实现故障自动转移，当Kafka<code>集群</code>中一个<code>broker</code>失效情况下仍然保证服务可用。在<code>Kafka</code>中发生复制时确保<code>partition</code>的日志能有序地写到其他节点上，N个<code>replicas</code>中，其中一个<code>replica</code>为<code>leader</code>，其他都为<code>follower</code>, <code>leader</code>处理<code>partition</code>的所有读写请求，与此同时，<code>follower</code>会被动定期地去复制<code>leader</code>上的数据。</p>
<p>如下图所示，<code>Kafka</code>集群中有4个<code>broker</code>, 某<code>topic</code>有3个<code>partition</code>,且复制因子即副本个数也为3：</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png-20220105164106125.png" class="" title="这里写图片描述">
<p><code>Kafka</code>提供了数据复制算法保证，如果<code>leader</code>发生故障或挂掉，一个新<code>leader</code>被选举并被接受客户端的消息成功写入。<code>Kafka</code>确保从同步副本列表中选举一个副本为<code>leader</code>，或者说<code>follower</code>追赶<code>leader</code>数据。<code>leader</code>负责维护和跟踪<code>ISR</code>(<code>In-Sync Replicas</code>的缩写，表示副本同步队列，具体可参考下节)中所有<code>follower</code>滞后的状态。当<code>producer</code>发送一条消息到<code>broker</code>后，<code>leader</code>写入消息并复制到所有<code>follower</code>。消息提交之后才被成功复制到所有的同步副本。消息复制延迟受最慢的<code>follower</code>限制，重要的是快速检测慢副本，如果<code>follower</code>“落后”太多或者失效，<code>leader</code>将会把它从<code>ISR</code>中删除。</p>
<p>另外每个<code>replica</code>都有<code>HW</code>,<code>leader</code>和<code>follower</code>各自负责更新自己的<code>HW</code>的状态。对于<code>leader</code>新写入的消息，<code>consumer</code>不能立刻消费，<code>leader</code>会等待该消息被所有ISR中的<code>replicas</code>同步后更新<code>HW</code>，此时消息才能被<code>consumer</code>消费。这样就保证了如果<code>leader</code>所在的<code>broker</code>失效，该消息仍然可以从新选举的<code>leader</code>中获取。对于来自内部<code>broker</code>的读取请求，没有<code>HW</code>的限制。</p>
<p>下图详细的说明了当<code>producer</code>生产消息至<code>broker</code>后，ISR以及HW和LEO的流转过程：</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png-20220105164408305.png" class="" title="这里写图片描述">
<p>由此可见，<code>Kafka</code>的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，同步复制要求所有能工作的<code>follower</code>都复制完，这条消息才会被<code>commit</code>，这种复制方式极大的影响了吞吐率。而异步复制方式下，<code>follower</code>异步的从<code>leader</code>复制数据，数据只要被<code>leader</code>写入<code>log</code>就被认为已经<code>commit</code>，这种情况下如果<code>follower</code>都还没有复制完，落后于<code>leader</code>时，突然<code>leader</code>宕机，则会丢失数据。而<code>Kafka</code>的这种使用<code>ISR</code>的方式则很好的均衡了确保数据不丢失以及吞吐率。</p>
<p><code>Kafka</code>的<code>ISR</code>的管理最终都会反馈到<code>Zookeeper</code>节点上。具体位置为：<code>/brokers/topics/[topic]/partitions/[partition]/state</code>。目前有两个地方会对这个<code>Zookeeper</code>的节点进行维护：</p>
<ul>
<li>
<p><code>Controller</code>来维护：<code>Kafka</code>集群中的其中一个<code>Broker</code>会被选举为<code>Controller</code>，主要负责<code>Partition</code>管理和副本状态管理，也会执行类似于重分配<code>partition</code>之类的管理任务。在符合某些特定条件下，<code>Controller</code>下的<code>LeaderSelector</code>会选举新的<code>leader</code>，<code>ISR</code>和新的<code>leader_epoch</code>及<code>controller_epoch</code>写入<code>Zookeeper</code>的相关节点中。同时发起<code>LeaderAndIsrRequest</code>通知所有的<code>replicas</code>。</p>
</li>
<li>
<p><code>leader</code>来维护：<code>leader</code>有单独的线程定期检测<code>ISR</code>中<code>follower</code>是否脱离<code>ISR</code>, 如果发现<code>ISR</code>变化，则会将新的<code>ISR</code>的信息返回到<code>Zookeeper</code>的相关节点中。</p>
</li>
</ul>
<h2 id="3-2-Kafka-生产者">3.2 Kafka 生产者</h2>
<h3 id="3-2-1-分区策略">3.2.1  分区策略</h3>
<p>1）分区的原因</p>
<p>​	（1）<strong>方便在集群中扩展</strong>，每个 <code>Partition</code> 可以通过调整以适应它所在的机器，而一个  <code>topic</code>又可以有多个 <code>Partition</code> 组成，因此整个集群就可以适应任意大小的数据了；</p>
<p>​	（2）<strong>可以提高并发</strong>，因为可以以 <code>Partition</code> 为单位读写了。</p>
<p>2）分区的原则</p>
<p>​	我们需要将 <code>producer</code> 发送的数据封装成一个 <code>ProducerRecord</code> 对象。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220105160759755-1370080.png" class="" title="image-20220105160759755">
<p>（1）指明   <code>partition</code>  的情况下，直接将指明的值直接作为   <code>partiton</code>  值；（权重）</p>
<p>（2）没有指明   <code>partition</code>  值但有   <code>key</code>  的情况下，将   <code>key</code>  的   <code>hash</code>  值与   <code>topic</code>  的   <code>partition</code> 数进行取余得到   partition  值；（hash）</p>
<p>（3）既没有 <code>partition</code>  值又没有 key  值的情况下，第一次调用时随机生成一个整数（后 面每次调用在这个整数上自增），将这个值与 <code>topic</code>  可用的 <code>partition</code>  总数取余得到 <code>partition</code> 值，也就是常说的 <code>round-robin</code>  算法。(轮询)</p>
<h3 id="3-2-2-数据可靠性保证">3.2.2  数据可靠性保证</h3>
<p>为保证 <code>producer</code> 发送的数据，能可靠的发送到指定的 <code>topic</code>，<code>topic</code> 的每个 <code>partition</code> 收到 <code>producer</code> 发送的数据后，都需要向 <code>producer</code> 发送 <code>ack</code>（<code>acknowledgement</code> 确认收到），如果 <code>producer</code> 收到 <code>ack</code>，就会进行下一轮的发送，否则重新发送数据。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220105161526377.png" class="" title="image-20220105161526377">
<p><strong>1）副本数据同步策略</strong></p>
<table>
<thead>
<tr>
<th>方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>半数以上完成同步，就发 送  <code>ack</code></td>
<td>延迟低</td>
<td>选举新的 <code>leader</code> 时，容忍 n 台 节点的故障，需要 <code>2n+1</code> 个副 本</td>
</tr>
<tr>
<td>全部完成同步，才发送 <code>ack</code></td>
<td>选举新的 <code>leader</code> 时，容忍 n 台 节点的故障，需要 n+1 个副 本</td>
<td>延迟高</td>
</tr>
</tbody>
</table>
<p><code>Kafka</code> 选择了第二种方案，原因如下：</p>
<ol>
<li>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1个副本，而 <code>Kafka</code> 的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</li>
<li>虽然第二种方案的网络延迟会比较高，但网络延迟对  <code>Kafka</code> 的影响较小。</li>
</ol>
<blockquote>
<ul>
<li>半数以上方案的缺点解释：宕机的N个机器，它们可能是同步好数据的那部分，也可能是没有同步好的那部分。如果坏掉的是同步好的那部分，那我们只需要N+1个副本(多出来的这个副本是仅仅或者说专门用来备份的节点机器，懂我意思吧)，如果坏掉的不是同步好的那部分，本身没有同步的数据，而且还缺一份备份，所以需要2N+1</li>
<li>全部同步才发送<code>ack</code>的方案：因为是所有的<code>follower</code>都同步好了，参照上面的解释，我们就仅仅需要N+1个副本就好。</li>
</ul>
</blockquote>
<p><strong>2）ISR</strong></p>
<p>采用第二种方案之后，设想以下情景：<code>leader</code> 收到数据，所有 <code>follower</code> 都开始同步数据， 但有一个 <code>follower</code>，因为某种故障，迟迟不能与 <code>leader</code> 进行同步，那 <code>leader</code> 就要一直等下去， 直到它完成同步，才能发送 <code>ack</code>。这个问题怎么解决呢？</p>
<p><code>Leader</code> 维护了一个动态的 <code>in-sync replica set (ISR)</code>，意为和 <code>leader</code> 保持同步的 <code>follower</code> 集 合。当 <code>ISR</code> 中的 <code>follower</code> 完成数据的同步之后，<code>leader</code> 就会给 <code>follower</code> 发送 <code>ack</code>。如果 <code>follower</code> 长时间未 向 <code>leader</code> 同 步 数 据 ， 则 该 <code>follower</code> 将 被 踢 出<code> ISR</code> ， 该 时 间 阈 值 由<code>replica.lag.time.max.ms</code> 参数设定。<code>Leader</code> 发生故障之后，就会从  <code>ISR</code> 中选举新的  <code>leader</code>。</p>
<p>默认情况下<code>Kafka</code>的<code>replica</code>数量为1，即每个<code>partition</code>都有一个唯一的<code>leader</code>，为了确保消息的可靠性，通常应用中将其值(由<code>broker</code>的参数<code>offsets.topic.replication.factor</code>指定)大小设置为大于1，比如3。 所有的副本（<code>replicas</code>）统称为<code>Assigned Replicas</code>，即<code>AR</code>。<code>ISR</code>是<code>AR</code>中的一个子集，由<code>leader</code>维护<code>ISR</code>列表，<code>follower</code>从<code>leader</code>同步数据有一些延迟（包括延迟时间<code>replica.lag.time.max.ms</code>和延迟条数<code>replica.lag.max.messages</code>两个维度, 当前最新的版本<code>0.10.x</code>中只支持<code>replica.lag.time.max.ms</code>这个维度），任意一个超过阈值都会把<code>follower</code>剔除出<code>ISR</code>, 存入<code>OSR</code>（<code>Outof-Sync Replicas</code>）列表，新加入的<code>follower</code>也会先存放在<code>OSR</code>中。<code>AR=ISR+OSR</code>。</p>
<p><code>Kafka 0.9.0.0</code>版本后移除了<code>replica.lag.max.messages</code>参数，只保留了<code>replica.lag.time.max.ms</code>作为ISR中副本管理的参数。为什么这样做呢？</p>
<p><code>replica.lag.max.messages</code>表示当前某个副本落后<code>leader</code>的消息数量超过了这个参数的值，那么<code>leader</code>就会把<code>follower</code>从<code>ISR</code>中删除。假设设置<code>replica.lag.max.messages</code>=4，那么如果<code>producer</code>一次传送至<code>broker</code>的消息数量都小于4条时，因为在<code>leader</code>接受到<code>producer</code>发送的消息之后而<code>follower</code>副本开始拉取这些消息之前，<code>follower</code>落后<code>leader</code>的消息数不会超过4条消息，故此没有<code>follower</code>移出<code>ISR</code>，所以这时候<code>replica.lag.max.message</code>的设置似乎是合理的。但是<code>producer</code>发起瞬时高峰流量，<code>producer</code>一次发送的消息超过4条时，也就是超过<code>replica.lag.max.messages</code>，此时follower都会被认为是与<code>leader</code>副本不同步了，从而被踢出了<code>ISR</code>。但实际上这些<code>follower</code>都是存活状态的且没有性能问题。那么在之后追上<code>leader</code>,并被重新加入了<code>ISR</code>。于是就会出现它们不断地剔出<code>ISR</code>然后重新回归<code>ISR</code>，这无疑增加了无谓的性能损耗。而且这个参数是<code>broker</code>全局的。设置太大了，影响真正“落后”<code>follower</code>的移除；设置的太小了，导致<code>follower</code>的频繁进出。无法给定一个合适的<code>replica.lag.max.messages</code>的值，故此，新版本的<code>Kafka</code>移除了这个参数。</p>
<blockquote>
<p><code>ISR</code>包括<code>leader</code>和<code>follow</code></p>
</blockquote>
<p><strong>3）<code>ack</code> 应答机制</strong><br>
对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失， 所以没必要等 <code>ISR</code> 中的  <code>follower</code> 全部接收成功。所以  <code>Kafka</code> 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡， 选择以下的配置。</p>
<p>当<code>producer</code>向<code>leader</code>发送数据时，可以通过<code>request.required.acks</code>参数来设置数据可靠性的级别：</p>
<ul>
<li><strong>1</strong>（默认）：这意味着<code>producer</code>在<code>ISR</code>中的<code>leader</code>已成功收到数据并得到确认。如果<code>leader</code>宕机了，则会丢失数据。</li>
<li><strong>0</strong>：这意味着<code>producer</code>无需等待来自<code>broker</code>的确认而继续发送下一批消息。这种情况下数据传输效率最高，但是数据可靠性确是最低的。</li>
<li><strong>-1</strong>：<code>producer</code>需要等待ISR中的所有<code>follower</code>都确认接收到数据后才算一次发送完成，可靠性最高。但是这样也不能保证数据不丢失，比如当<code>ISR</code>中只有<code>leader</code>时（前面<code>ISR</code>那一节讲到，<code>ISR</code>中的成员由于某些情况会增加也会减少，最少就只剩一个<code>leader</code>），这样就变成了<code>acks</code>=1的情况。</li>
</ul>
<p>如果要提高数据的可靠性，在设置<code>request.required.acks</code>=-1的同时，也要<code>min.insync.replicas</code>这个参数(可以在<code>broker</code>或者<code>topic</code>层面进行设置)的配合，这样才能发挥最大的功效。<code>min.insync.replicas</code>这个参数设定<code>ISR</code>中的最小副本数是多少，默认值为<code>1</code>，当且仅当<code>request.required.acks</code>参数设置为<code>-1</code>时，此参数才生效。如果ISR中的副本数少于<code>min.insync.replicas</code>配置的数量时，客户端会返回异常：<code>org.apache.kafka.common.errors.NotEnoughReplicasExceptoin</code>: <code>Messages are rejected since there are fewer in-sync replicas than required。</code></p>
<p>接下来对<code>acks</code>=1和-1的两种情况进行详细分析：</p>
<p><strong>1. request.required.acks=1</strong></p>
<p><code>producer</code>发送数据到<code>leader</code>，<code>leader</code>写本地日志成功，返回客户端成功；此时<code>ISR</code>中的副本还没有来得及拉取该消息，<code>leader</code>就宕机了，那么此次发送的消息就会丢失。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png-1439968.png" class="" title="这里写图片描述">
<ol start="2">
<li><strong>request.required.acks=-1</strong></li>
</ol>
<p>同步（<code>Kafka</code>默认为同步，即<code>producer.type=sync</code>）的发送模式，<code>replication.factor&gt;=2</code>且<code>min.insync.replicas&gt;=2</code>的情况下，不会丢失数据。</p>
<p>有两种典型情况。<code>acks=-1</code>的情况下（如无特殊说明，以下<code>acks</code>都表示为参数<code>request.required.acks</code>），数据发送到<code>leader</code>, <code>ISR</code>的<code>follower</code>全部完成数据同步后，<code>leader</code>此时挂掉，那么会选举出新的<code>leader</code>，数据不会丢失。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png-20220106113345033.png" class="" title="这里写图片描述">
<p><code>acks</code>=-1的情况下，数据发送到<code>leader</code>后 ，部分<code>ISR</code>的副本同步，<code>leader</code>此时挂掉。比如<code>follower1</code>和<code>follower2</code>都有可能变成新的<code>leader</code>, <code>producer</code>端会得到返回异常，<code>producer</code>端会重新发送数据，数据可能会重复。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png-20220106113413975.png" class="" title="这里写图片描述">
<p>当然上图中如果在<code>leader crash</code>的时候，<code>follower2</code>还没有同步到任何数据，而且<code>follower2</code>被选举为新的<code>leader</code>的话，这样消息就不会重复。</p>
<blockquote>
<p>注：Kafka只处理fail/recover问题,不处理Byzantine问题。</p>
</blockquote>
<h3 id="3-2-3-关于HW的进一步探讨">3.2.3 关于HW的进一步探讨</h3>
<p>考虑上图（即<code>acks=-1</code>,部分<code>ISR</code>副本同步）中的另一种情况，如果在<code>Leader</code>挂掉的时候，<code>follower1</code>同步了消息4,5，<code>follower2</code>同步了消息4，与此同时<code>follower2</code>被选举为<code>leader</code>，那么此时<code>follower1</code>中的多出的消息5该做如何处理呢？</p>
<p>这里就需要<code>HW</code>的协同配合了。如前所述，一个<code>partition</code>中的<code>ISR</code>列表中，<code>leader</code>的<code>HW</code>是所有<code>ISR</code>列表里副本中最小的那个的<code>LEO</code>。类似于木桶原理，水位取决于最低那块短板。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png-20220106113832317.png" class="" title="这里写图片描述">
<p>如上图，某个<code>topic</code>的某<code>partition</code>有三个副本，分别为A、B、C。A作为<code>leader</code>肯定是<code>LEO</code>最高，B紧随其后，C机器由于配置比较低，网络比较差，故而同步最慢。这个时候A机器宕机，这时候如果B成为<code>leader</code>，假如没有<code>HW</code>，在A重新恢复之后会做同步(<code>makeFollower</code>)操作，在宕机时<code>log</code>文件之后直接做追加操作，而假如B的<code>LEO</code>已经达到了A的<code>LEO</code>，会产生数据不一致的情况，所以使用<code>HW</code>来避免这种情况。<br>
A在做同步操作的时候，先将<code>log</code>文件截断到之前自己的<code>HW</code>的位置，即3，之后再从B中拉取消息进行同步。</p>
<p>如果失败的<code>follower</code>恢复过来，它首先将自己的<code>log</code>文件截断到上次<code>checkpointed</code>时刻的<code>HW</code>的位置，之后再从<code>leader</code>中同步消息。<code>leader</code>挂掉会重新选举，新的<code>leader</code>会发送“指令”让其余的<code>follower</code>截断至自身的<code>HW</code>的位置然后再拉取新的消息。</p>
<blockquote>
<p>当ISR中的个副本的LEO不一致时，如果此时leader挂掉，选举新的leader时并不是按照LEO的高低进行选举，而是按照ISR中的顺序选举。</p>
</blockquote>
<h3 id="3-2-4-消息传输保障">3.2.4 消息传输保障</h3>
<p>将服务器的 <code>ACK</code> 级别设置为-1，可以保证 <code>Producer</code> 到 <code>Server</code> 之间不会丢失数据，即 <code>At Least Once </code>语义。相对的，将服务器 <code>ACK</code> 级别设置为 0，可以保证生产者每条消息只会被 发送一次，即 <code>At Most Once</code> 语义。</p>
<p><code>At Least Once</code> 可以保证数据不丢失，但是不能保证数据不重复；相对的，<code>At Least Once</code> 可以保证数据不重复，但是不能保证数据不丢失。但是，对于一些非常重要的信息，比如说 交易数据，下游数据消费者要求数据既不重复也不丢失，即 <code>Exactly Once</code> 语义。在 0.11 版 本以前的 <code>Kafka</code>，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局 去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。0.11 版本的 <code>Kafka</code>，引入了一项重大特性：幂等性。所谓的幂等性就是指 <code>Producer</code> 不论 向 <code>Server</code> 发送多少次重复数据，<code>Server</code> 端都只会持久化一条。幂等性结合 <code>At Least Once </code>语 义，就构成了 <code>Kafka</code> 的 <code>Exactly Once </code>语义。即：<br>
$$<br>
At Least Once + 幂等性   = Exactly Once<br>
$$<br>
要启用幂等性，只需要将 <code>Producer</code> 的参数中 <code>enable.idompotence </code>设置为 <code>true</code> 即可。<code>Kafka</code> 的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的 <code>Producer</code> 在 初始化的时候会被分配一个 <code>PID</code>，发往同一 <code>Partition</code> 的消息会附带 <code>Sequence Number</code>。而 <code>Broker</code> 端会对<code>&lt;PID, Partition, SeqNumber&gt;</code>做缓存，当具有相同主键的消息提交时，<code>Broker</code> 只 会持久化一条。</p>
<p>但是 <code>PID</code> 重启就会变化，同时不同的 <code>Partition</code> 也具有不同主键，所以幂等性无法保证跨分区跨会话的 <code>Exactly Once</code>。</p>
<h3 id="3-2-5-消息去重">3.2.5 消息去重</h3>
<p>如上一节所述，<code>Kafka</code>在<code>producer</code>端和<code>consumer</code>端都会出现消息的重复，这就需要去重处理。</p>
<p><code>Kafka</code>文档中提及<code>GUID(Globally Unique Identifier)</code>的概念，通过客户端生成算法得到每个消息的<code>unique id</code>，同时可映射至<code>broker</code>上存储的地址，即通过<code>GUID</code>便可查询提取消息内容，也便于发送方的幂等性保证，需要在<code>broker</code>上提供此去重处理模块，目前版本尚不支持。</p>
<p>针对<code>GUID</code>, 如果从客户端的角度去重，那么需要引入集中式缓存，必然会增加依赖复杂度，另外缓存的大小难以界定。</p>
<p>不只是<code>Kafka</code>, 类似<code>RabbitMQ</code>以及<code>RocketMQ</code>这类商业级中间件也只保障<code>at least once</code>, 且也无法从自身去进行消息去重。所以我们建议业务方根据自身的业务特点进行去重，比如业务消息本身具备幂等性，或者借助<code>Redis</code>等其他产品进行去重处理。</p>
<h3 id="3-2-6-高可靠性配置">3.2.6 高可靠性配置</h3>
<p><code>Kafka</code>提供了很高的数据冗余弹性，对于需要数据高可靠性的场景，我们可以增加数据冗余备份数<code>（replication.factor）</code>，调高最小写入副本数的个数<code>（min.insync.replicas）</code>等等，但是这样会影响性能。反之，性能提高而可靠性则降低，用户需要自身业务特性在彼此之间做一些权衡性选择。</p>
<p>要保证数据写入到<code>Kafka</code>是安全的，高可靠的，需要如下的配置：</p>
<p><code>topic</code>的配置：<code>replication.factor&gt;=3</code>,即副本数至少是3个；<code>2&lt;=min.insync.replicas&lt;=replication.factor</code><br>
<code>broker</code>的配置：<code>leader</code>的选举条件<code>unclean.leader.election.enable=false</code><br>
<code>producer</code>的配置：<code>request.required.acks=-1(all)，producer.type=sync</code></p>
<h2 id="3-3-Kafka-消费者">3.3 Kafka 消费者</h2>
<h3 id="3-3-1-消费方式">3.3.1  消费方式</h3>
<p><code>consumer</code> 采用<code>  pull</code>（拉）模式从 <code>broker</code> 中读取数据。<code>push</code>（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由  <code>broker</code> 决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成 <code>consumer</code> 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而  <code>pull</code> 模式则可以根据  <code>consumer</code> 的消费能力以适 当的速率消费消息。<code>pull</code> 模式不足之处是，如果 <code>kafka</code> 没有数据，消费者可能会陷入循环中，一直返回空数 据。针对这一点，<code>Kafka</code> 的消费者在消费数据时会传入一个时长参数 <code>timeout</code>，如果当前没有 数据可供消费，<code>consumer</code> 会等待一段时间之后再返回，这段时长即为 <code>timeout</code>。</p>
<h3 id="3-3-2-分区分配策略">3.3.2  分区分配策略</h3>
<p>一个  <code>consumer group</code> 中有多个 <code>consumer</code>，一个   <code>topic</code> 有多个 <code>partition</code>，所以必然会涉及 到 <code>partition</code> 的分配问题，即确定那个  <code>partition</code> 由哪个  <code>consumer</code> 来消费。<code>Kafka</code> 有两种分配策略，一是  <code>RoundRobin</code>，一是 <code>Range</code>。默认采用 <code>Range</code> 范围分区。 <code>Kafka</code>提供了消费者客户端参数 <code>partition.assignment.strategy</code> 用来设置消费者与订阅主题之间的分区分配策略。默认情况下，此参数的值为：<code>org.apache.kafka.clients.consumer.RangeAssignor</code>，即采用<code>RangeAssignor</code>分配策略。</p>
<p><strong>1）RoundRobin</strong></p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220106142144381.png" class="" title="image-20220106142144381">
<p><code>RoundRobin</code> 轮询分区策略，是把所有的 <code>partition</code> 和所有的 <code>consumer</code> 都列出来，然后按照 <code>hascode</code> 进行排序，最后通过轮询算法来分配 <code>partition</code> 给到各个消费者。</p>
<p>轮询分区分为如下两种情况：①同一消费组内所有消费者订阅的消息都是相同的    ②同一消费者组内的消费者组订阅的消息不相同</p>
<p>①如果同一消费组内，所有的消费者订阅的消息都是相同的，那么 <code>RoundRobin</code> 策略的分区分配会是均匀的。</p>
<p>例如：同一消费者组中，有 3 个消费者C0、C1和C2，都订阅了 2 个主题 t0  和 t1，并且每个主题都有 3 个分区(p0、p1、p2)，那么所订阅的所以分区可以标识为<code>t0p0、t0p1、t0p2、t1p0、t1p1、t1p2</code>。最终分区分配结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">RoundRobin</th>
</tr>
</thead>
<tbody>
<tr>
<td>消费者C0</td>
<td style="text-align:center">消费 t0p0 、t1p0 分区</td>
</tr>
<tr>
<td>消费者C1</td>
<td style="text-align:center">消费 t0p1 、t1p1 分区</td>
</tr>
<tr>
<td>消费者C2</td>
<td style="text-align:center">消费 t0p2 、t1p2 分区</td>
</tr>
</tbody>
</table>
<p>②如果同一消费者组内，所订阅的消息是不相同的，那么在执行分区分配的时候，就不是完全的轮询分配，有可能会导致分区分配的不均匀。如果某个消费者没有订阅消费组内的某个 topic，那么在分配分区的时候，此消费者将不会分配到这个 <code>topic</code> 的任何分区。</p>
<p>例如：同一消费者组中，有3个消费者C0、C1和C2，他们共订阅了 3 个主题：t0、t1 和 t2，这 3 个主题分别有 1、2、3 个分区(即:t0有1个分区<code>(p0)</code>，t1有2个分区<code>(p0、p1)</code>，t2有3个分区<code>(p0、p1、p2))</code>，即整个消费者所订阅的所有分区可以标识为 <code>t0p0、t1p0、t1p1、t2p0、t2p1、t2p2</code>。具体而言，消费者C0订阅的是主题t0，消费者C1订阅的是主题t0和t1，消费者C2订阅的是主题t0、t1和t2，最终分区分配结果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">RoundRobin</th>
</tr>
</thead>
<tbody>
<tr>
<td>消费者C0</td>
<td style="text-align:center">消费 t0p0</td>
</tr>
<tr>
<td>消费者C1</td>
<td style="text-align:center">消费 t1p0 分区</td>
</tr>
<tr>
<td>消费者C2</td>
<td style="text-align:center">消费 t1p1、t2p0、t2p1、t2p2 分区</td>
</tr>
</tbody>
</table>
<p><strong>RoundRobin轮询分区的弊端：</strong></p>
<blockquote>
<p>从如上实例，可以看到RoundRobin策略也并不是十分完美，这样分配其实并不是最优解，因为完全可以将分区 t1p1 分配给消费者 C1。</p>
<p>所以，如果想要使用RoundRobin 轮询分区策略，必须满足如下两个条件：</p>
<p>①每个消费者订阅的主题，必须是相同的</p>
<p>②每个主题的消费者实例都是相同的。(即：上面的第一种情况，才优先使用 RoundRobin 轮询分区策略)</p>
</blockquote>
<p><strong>2）Range</strong></p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220106142208609.png" class="" title="image-20220106142208609">
<p><code>Range</code> 范围分区策略是对每个 <code>topic</code> 而言的。首先对同一个 <code>topic</code> 里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。假如现在有 10 个分区，3 个消费者，排序后的分区将会是0,1,2,3,4,5,6,7,8,9；消费者排序完之后将会是<code>C1-0,C2-0,C3-0</code>。通过 <strong><code>partitions</code>数/<code>consumer</code>数</strong> 来决定每个消费者应该消费几个分区。如果除不尽，那么前面几个消费者将会多消费 1 个分区。</p>
<blockquote>
<p>例如，10/3 = 3 余 1 ，除不尽，那么 消费者 C1-0 便会多消费 1 个分区，最终分区分配结果如下：</p>
</blockquote>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">Range分区</th>
</tr>
</thead>
<tbody>
<tr>
<td>C1-0</td>
<td style="text-align:center">消费 0,1,2,3 分区</td>
</tr>
<tr>
<td>C2-0</td>
<td style="text-align:center">消费 4,5,6 分区</td>
</tr>
<tr>
<td>C3-0</td>
<td style="text-align:center">消费 7,8,9 分区(如果有11 个分区的话，C1-0 将消费0,1,2,3 分区，C2-0 将消费4,5,6,7分区  C3-0 将消费 8,9,10 分区)</td>
</tr>
</tbody>
</table>
<p><strong><code>Range</code> 范围分区的弊端：</strong></p>
<blockquote>
<p>如上，只是针对 1 个 <code>topic</code> 而言，<code>C1-0</code>消费者多消费<code>1</code>个分区影响不是很大。如果有 N 多个 <code>topic</code>，那么针对每个 <code>topic</code>，消费者<code>C1-0</code>都将多消费 1 个分区，<code>topic</code>越多，C1-0 消费的分区会比其他消费者明显多消费 N 个分区。这就是 <code>Range</code> 范围分区的一个很明显的弊端了.</p>
</blockquote>
<p><strong>2.什么时候触发分区分配策略</strong><br>
当出现以下几种情况时，<code>Kafka</code> 会进行一次分区分配操作，即 <code>Kafka</code> 消费者端的 <code>Rebalance</code> 操作</p>
<p>① 同一个 <code>consumer</code> 消费者组<code>group.id</code>中，新增了消费者进来，会执行 <code>Rebalance</code> 操作</p>
<p>② 消费者离开当期所属的 <code>consumer group</code>组。比如 主动停机  或者  宕机</p>
<p>③ 分区数量发生变化时(即 <code>topic</code> 的分区数量发生变化时)</p>
<p>④ 消费者主动取消订阅</p>
<p><code>Kafka</code> 消费端的 <code>Rebalance</code> 机制，规定了一个<code>Consumer group</code>下的所有 <code>consumer</code> 如何达成一致来分配订阅 <code>topic</code> 的每一个分区。而具体如何执行分区策略，就是上面提到的 <code>Range</code> 范围分区 和 <code>RoundRobin</code> 轮询分区 两种内置的分区策略。</p>
<p><code>Kafka</code> 对于分区分配策略这块，也提供了可插拔式的实现方式，除了上面两种分区分配策略外，我们也可以创建满足自己使用的分区分配策略，即：<strong>自定义分区策略</strong></p>
<h3 id="3-3-3-offset-的维护">3.3.3 offset 的维护</h3>
<p>由于 <code>consumer</code> 在消费过程中可能会出现断电宕机等故障，<code>consumer</code> 恢复后，需要从故障前的位置的继续消费，所以 <code>consumer</code> 需要实时记录自己消费到了哪个 <code>offset</code>，以便故障恢 复后继续消费。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220106142242884.png" class="" title="image-20220106142242884">
<p><code>Kafka 0.9</code> 版本之前，<code>consumer</code> 默认将  <code>offset</code> 保存在  <code>Zookeeper</code> 中，从  <code>0.9 </code>版本开始， <code>consumer</code> 默认将 <code>offset</code> 保存在 <code>Kafka</code> 一个内置的  <code>topic</code> 中，该 <code>topic</code> 为<code>__consumer_offsets</code>。</p>
<p>1）修改配置文件 consumer.properties</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">exclude.internal.topics</span>=<span class="hljs-literal">false</span><br></code></pre></td></tr></table></figure>
<p>2）读取 offset 0.11.0.0 之前版本:</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">bin/kafka-console-consumer.sh   <span class="hljs-params">--topic</span>   __consumer_offsets   <span class="hljs-params">--hadoop102</span><span class="hljs-function">:2181</span> zookeeper <span class="hljs-params">--formatter</span> <span class="hljs-string">&quot;kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter&quot;</span> <span class="hljs-params">--consumer</span>.config config/consumer.properties <span class="hljs-params">--from-beginning</span><br></code></pre></td></tr></table></figure>
<p>0.11.0.0 之后版本(含):</p>
<figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dsconfig"><span class="hljs-string">bin</span>/<span class="hljs-string">kafka-console-consumer</span>.<span class="hljs-string">sh</span>   <span class="hljs-built_in">--topic</span>   <span class="hljs-string">__consumer_offsets</span>   <span class="hljs-built_in">--hadoop102:2181</span> <span class="hljs-string">zookeeper</span> <br><span class="hljs-built_in">--formatter</span> <span class="hljs-string">&quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageForm atter&quot;</span>  <span class="hljs-built_in">--consumer.config</span>  <span class="hljs-string">config</span>/<span class="hljs-string">consumer</span>.<span class="hljs-string">properties</span> <span class="hljs-built_in">--from-</span> <span class="hljs-string">beginning</span><br></code></pre></td></tr></table></figure>
<h2 id="3-4-Leader选举">3.4 Leader选举</h2>
<p>一条消息只有被<code>ISR</code>中的所有<code>follower</code>都从<code>leader</code>复制过去才会被认为已提交。这样就避免了部分数据被写进了<code>leader</code>，还没来得及被任何<code>follower</code>复制就宕机了，而造成数据丢失。而对于<code>producer</code>而言，它可以选择是否等待消息<code>commit</code>，这可以通过<code>request.required.acks</code>来设置。这种机制确保了只要<code>ISR</code>中有一个或者以上的<code>follower</code>，一条被<code>commit</code>的消息就不会丢失。</p>
<p>有一个很重要的问题是当<code>leader</code>宕机了，怎样在<code>follower</code>中选举出新的<code>leader</code>，因为<code>follower</code>可能落后很多或者直接<code>crash</code>了，所以必须确保选择“最新”的<code>follower</code>作为新的<code>leader</code>。一个基本的原则就是，如果<code>leader</code>不在了，新的<code>leader</code>必须拥有原来的<code>leader commit</code>的所有消息。这就需要做一个折中，如果<code>leader</code>在一个消息被<code>commit</code>前等待更多的<code>follower</code>确认，那么在它挂掉之后就有更多的follower可以成为新的<code>leader</code>，但这也会造成吞吐率的下降。</p>
<p>一种非常常用的选举<code>leader</code>的方式是“少数服从多数”，<code>Kafka</code>并不是采用这种方式。这种模式下，如果我们有2f+1个副本，那么在<code>commit</code>之前必须保证有f+1个<code>replica</code>复制完消息，同时为了保证能正确选举出新的<code>leader</code>，失败的副本数不能超过f个。这种方式有个很大的优势，系统的延迟取决于最快的几台机器，也就是说比如副本数为3，那么延迟就取决于最快的那个<code>follower</code>而不是最慢的那个。“少数服从多数”的方式也有一些劣势，为了保证<code>leader</code>选举的正常进行，它所能容忍的失败的<code>follower</code>数比较少，如果要容忍1个<code>follower</code>挂掉，那么至少要3个以上<code>的</code>副本，如果要容忍2个<code>follower</code>挂掉，必须要有5个以上的副本。也就是说，在生产环境下为了保证较高的容错率，必须要有大量的副本，而大量的副本又会在大数据量下导致性能的急剧下降。这种算法更多用在<code>Zookeeper</code>这种共享集群配置的系统中而很少在需要大量数据的系统中使用的原因。<code>HDFS</code>的<code>HA</code>功能也是基于“少数服从多数”的方式，但是其数据存储并不是采用这样的方式。</p>
<p>实际上，<code>leader</code>选举的算法非常多，比如<code>Zookeeper</code>的<code>Zab</code>、<code>Raft</code>以及<code>Viewstamped Replication</code>。而<code>Kafka</code>所使用的<code>leader</code>选举算法更像是微软的<code>PacificA</code>算法。</p>
<p><code>Kafka</code>在<code>Zookeeper</code>中为每一个<code>partition</code>动态的维护了一个<code>ISR</code>，这个<code>ISR</code>里的所有<code>replica</code>都跟上了<code>leader</code>，只有<code>ISR</code>里的成员才能有被选为<code>leader</code>的可能（<code>unclean.leader.election.enable=false</code>）。在这种模式下，对于f+1个副本，一个<code>Kafka topic</code>能在保证不丢失已经<code>commit</code>消息的前提下容忍f个副本的失败，在大多数使用场景下，这种模式是十分有利的。事实上，为了容忍f个副本的失败，“少数服从多数”的方式和ISR在<code>commit</code>前需要等待的副本的数量是一样的，但是ISR需要的总的副本的个数几乎是“少数服从多数”的方式的一半。</p>
<p>上文提到，在<code>ISR</code>中至少有一个<code>follower</code>时，<code>Kafka</code>可以确保已经<code>commit</code>的数据不丢失，但如果某一个<code>partition</code>的所有<code>replica</code>都挂了，就无法保证数据不丢失了。这种情况下有两种可行的方案：</p>
<p>等待<code>ISR</code>中任意一个<code>replica</code>“活”过来，并且选它作为<code>leader</code>选择第一个“活”过来的<code>replica</code>（并不一定是在<code>ISR</code>中）作为<code>leader</code>这就需要在可用性和一致性当中作出一个简单的抉择。如果一定要等待<code>ISR</code>中的<code>replica</code>“活”过来，那不可用的时间就可能会相对较长。而且如果<code>ISR</code>中所有的<code>replica</code>都无法“活”过来了，或者数据丢失了，这个<code>partition</code>将永远不可用。选择第一个“活”过来的<code>replica</code>作为<code>leader</code>,而这个<code>replica</code>不是ISR中的<code>replica</code>,那即使它并不保障已经包含了所有已<code>commit</code>的消息，它也会成为<code>leader</code>而作为<code>consumer</code>的数据源。默认情况下，<code>Kafka</code>采用第二种策略，即<code>unclean.leader.election.enable=true</code>，也可以将此参数设置为false来启用第一种策略。</p>
<p><code>unclean.leader.election.enable</code>这个参数对于<code>leader</code>的选举、系统的可用性以及数据的可靠性都有至关重要的影响。下面我们来分析下几种典型的场景。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png-20220106142829417.png" class="" title="这里写图片描述">
<p>如果上图所示，假设某个<code>partition</code>中的副本数为3，<code>replica-0, replica-1, replica-2</code>分别存放在<code>broker0, broker1</code>和<code>broker2</code>中。<code>AR=(0,1,2)，ISR=(0,1)</code>。<br>
设置<code>request.required.acks=-1, min.insync.replicas=2，unclean.leader.election.enable=false</code>。这里将<code>broker0</code>中的副本也称之为<code>broker0</code>起初<code>broker0</code>为<code>leader</code>，<code>broker1</code>为<code>follower</code>。</p>
<ul>
<li>
<p>当<code>ISR</code>中的<code>replica-0</code>出现<code>crash</code>的情况时，<code>broker1</code>选举为新的<code>leader[ISR=(1)]</code>，因为受<code>min.insync.replicas=2</code>影响，<code>write</code>不能服务，但是<code>read</code>能继续正常服务。此种情况恢复方案：</p>
<ol>
<li>尝试恢复(重启)<code>replica-0</code>，如果能起来，系统正常；</li>
<li>如果<code>replica-0</code>不能恢复，需要将<code>min.insync.replicas</code>设置为1，恢复<code>write</code>功能。</li>
</ol>
</li>
<li>
<p>当<code>ISR</code>中的<code>replica-0</code>出现<code>crash</code>，紧接着<code>replica-1</code>也出现了<code>crash</code>, 此时<code>[ISR=(1),leader=-1]</code>,不能对外提供服务，此种情况恢复方案：</p>
<ol>
<li>尝试恢复<code>replica-0</code>和<code>replica-1</code>，如果都能起来，则系统恢复正常；</li>
<li>如果<code>replica-0</code>起来，而<code>replica-1</code>不能起来，这时候仍然不能选出<code>leader</code>，因为当设置<code>unclean.leader.election.enable=false</code>时，<code>leader</code>只能从<code>ISR</code>中选举，当<code>ISR</code>中所有副本都失效之后，需要<code>ISR</code>中最后失效的那个副本能恢复之后才能选举<code>leader</code>, 即<code>replica-0</code>先失效，<code>replica-1</code>后失效，需要<code>replica-1</code>恢复后才能选举<code>leader</code>。保守的方案建议<code>unclean.leader.election.enable</code>设置为<code>true</code>,但是这样会有丢失数据的情况发生，这样可以恢复<code>read</code>服务。同样需要将<code>min.insync.replicas</code>设置为1，恢复<code>write</code>功能；</li>
<li><code>replica-1</code>恢复，<code>replica-0</code>不能恢复，这个情况上面遇到过，<code>read</code>服务可用，需要将<code>min.insync.replicas</code>设置为1，恢复<code>write</code>功能；</li>
<li><code>replica-0</code>和<code>replica-1</code>都不能恢复，这种情况可以参考情形2.</li>
</ol>
</li>
<li>
<p>当<code>ISR</code>中的<code>replica-0, replica-1</code>同时宕机,此时<code>[ISR=(0,1)]</code>,不能对外提供服务，此种情况恢复方案：尝试恢复<code>replica-0</code>和<code>replica-1</code>，当其中任意一个副本恢复正常时，对外可以提供<code>read</code>服务。直到2个副本恢复正常，<code>write</code>功能才能恢复，或者将将<code>min.insync.replicas</code>设置为1。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220106145637929.png" class="" title="image-20220106145637929">
</li>
</ul>
<h2 id="3-5-Kafka-高效读写数据">3.5 Kafka  高效读写数据</h2>
<p><strong>1）顺序写磁盘</strong></p>
<p><code>Kafka</code> 的 <code>producer</code> 生产数据，要写入到 <code>log</code> 文件中，写的过程是一直追加到文件末端， 为顺序写。官网有数据表明，同样的磁盘，顺序写能到  600M/s，而随机写只有  100K/s。这 与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p>
<p><strong>2）零复制技术</strong></p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220106145550166.png" class="" title="image-20220106145550166">
<h2 id="3-6-Kafka-事务">3.6 Kafka 事务</h2>
<p><code>Kafka</code> 从 0.11 版本开始引入了事务支持。事务可以保证  <code>Kafka</code> 在 <code>Exactly Once</code> 语义的基 础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p>
<h3 id="3-6-1-Producer-事务">3.6.1 Producer 事务</h3>
<p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的 <code>Transaction ID</code>，并将 <code>Producer</code> 获得的 <code>PID </code>和 <code>Transaction ID</code> 绑定。这样当 <code>Producer</code> 重启后就可以通过正在进行的 <code>Transaction ID </code>获得原来的 <code>PID</code>。</p>
<p>为了管理 <code>Transaction</code>，<code>Kafka</code> 引入了一个新的组件<code> Transaction Coordinator</code>。<code>Producer</code> 就 是通过和 <code>Transaction Coordinator</code> 交互获得 <code>Transaction ID </code>对应的任务状态。<code>Transaction Coordinator </code>还负责将事务所有写入 <code>Kafka</code> 的一个内部 <code>Topic</code>，这样即使整个服务重启，由于 事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p>
<h3 id="3-6-2-Consumer-事务">3.6.2 Consumer 事务</h3>
<p>上述事务机制主要是从 <code>Producer</code> 方面考虑，对于 <code>Consumer</code> 而言，事务的保证就会相对 较弱，尤其时无法保证 <code>Commit</code> 的信息被精确消费。这是由于 <code>Consumer</code> 可以通过 <code>offset</code> 访 问任意信息，而且不同的 <code>Segment File</code> 生命周期不同，同一事务的消息可能会出现重启后被 删除的情况。</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/dajiangdahe/categories/kafka/">kafka</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/dajiangdahe/tags/kafka/">kafka</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/dajiangdahe/2022/01/05/%E3%80%90%E6%94%BF%E6%B2%BB%E3%80%91%E5%8A%A8%E7%89%A9%E5%86%9C%E5%9C%BA/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">动物农场</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/dajiangdahe/2022/01/03/zookeeper_kafka_kafka-Manager%E5%8D%95%E6%9C%BA%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/">
                        <span class="hidden-mobile">Zookeeper_kafka_kafka-Manager单机集群环境安装</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
    
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        京ICP证123456号
      </a>
    </span>
    
      
        <span>
          <a
            href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=12345678"
            rel="nofollow noopener"
            class="beian-police"
            target="_blank"
          >
            
              <span style="visibility: hidden; width: 0">|</span>
              <img src="/dajiangdahe/img/police_beian.png" alt="police-icon"/>
            
            <span>京公网安备12345678号</span>
          </a>
        </span>
      
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/dajiangdahe/js/events.js" ></script>
<script  src="/dajiangdahe/js/plugins.js" ></script>

<!-- Plugins -->




  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/dajiangdahe/js/local-search.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>












  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/dajiangdahe/js/boot.js" ></script>


</body>
</html>
