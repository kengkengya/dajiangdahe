

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/dajiangdahe/img/favicon.png">
  <link rel="icon" href="/dajiangdahe/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="Hello,here is kengkeng&#39;s blog.">
  <meta name="author" content="kengkeng">
  <meta name="keywords" content="">
  
  <title>Kafka从入门到放弃 - kengkeng&#39;s life</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/dajiangdahe/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/dajiangdahe/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"kengkengya.github.io","root":"/dajiangdahe/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":1},"lazyload":{"enable":false,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/dajiangdahe/js/utils.js" ></script>
  <script  src="/dajiangdahe/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/dajiangdahe/">&nbsp;<strong>kengkeng's life</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/dajiangdahe/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/dajiangdahe/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/dajiangdahe/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/dajiangdahe/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/dajiangdahe/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/dajiangdahe/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Kafka从入门到放弃">
              
            </span>

            
              <div class="mt-3">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-author" aria-hidden="true"></i>
      kengkeng
    </span>
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-01-04 18:51" pubdate>
        2022年1月4日 晚上
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      4.4k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      50
       分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Kafka从入门到放弃</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：8 分钟前
                
              </p>
            
            <div class="markdown-body">
              <h1>第 1章 Kafka 概述</h1>
<h2 id="1-1-定义"><strong>1.1</strong> <strong>定义</strong></h2>
<p><code>Kafka</code> 是一个分布式的基于发布/订阅模式的消息队列（<code>Message Queue</code>），主要应用于大数据实时处理领域。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png-20220105165020501.png" class="" title="img">
<p>一个典型的Kafka体系架构包括若干Producer（可以是服务器日志，业务数据，页面前端产生的page view等等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer (Group)，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。Producer使用push(推)模式将消息发布到broker，Consumer使用pull(拉)模式从broker订阅并消费消息。</p>
<h2 id="1-2-消息队列"><strong>1.2</strong> <strong>消息队列</strong></h2>
<h3 id="1-2-1-传统消息队列的应用场景"><strong>1.2.1</strong> 传统消息队列的应用场景</h3>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220104190400222.png" class="" title="image-20220104190400222"> 
<p><strong>使用消息队列的好处</strong></p>
<p>1） 解耦</p>
<p>允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p>
<p>2） 可恢复性</p>
<p>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</p>
<p>3） 缓冲</p>
<p>有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致 的情况。</p>
<p>4）灵活性   &amp;  峰值处理能力</p>
<p>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。 如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列 能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</p>
<p>5）异步通信</p>
<p>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户 把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要 的时候再去处理它们。</p>
<h3 id="1-2-2-消息队列的两种模式">1.2.2  消息队列的两种模式</h3>
<p><strong>（1）点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）</strong></p>
<p>消息生产者生产消息发送到 <code>Queue</code> 中，然后消息消费者从 <code>Queue</code> 中取出并且消费消息。 消息被消费以后，<code>queue</code> 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。 <code>Queue</code> 支 持 存 在 多 个 消 费 者 ， 但 是 对 一 个 消 息 而 言 ， 只 会 有 一 个 消 费 者 可 以 消 费 。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220104190607741.png" class="" title="image-20220104190607741">
<p><strong>（2）发布/订阅模式（一对多，消费者消费数据之后不会清除消息）</strong><br>
消息生产者（发布）将消息发布到  <code>topic</code> 中，同时有多个消息消费者（订阅）消费该消 息。和点对点方式不同，发布到  <code>topic</code> 的消息会被所有订阅者消费。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220104190623124.png" class="" title="image-20220104190623124">
<h2 id="1-3-Kafka-基础架构">1.3 Kafka 基础架构</h2>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220104190748143.png" class="" title="image-20220104190748143">
<p>1）<strong><code>Producer</code></strong>  ：消息生产者，就是向  <code>kafka broker</code> 发消息的客户端；</p>
<p>2）<strong><code>Consumer</code></strong>  ：消息消费者，向  <code>kafka broker </code>取消息的客户端；</p>
<p>3）<code>**Consumer Group  （CG）**</code>：消费者组，由多个 <code>consumer</code> 组成。消费者组内每个消费者负 责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所 有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>
<p>4）<strong><code>Broker</code></strong>  ：一台 <code>kafka</code> 服务器就是一个 <code>broker</code>。一个集群由多个 <code>broker</code> 组成。一个 <code>broker</code>可以容纳多个 <code>topic</code>。</p>
<p>5）<strong><code>Topic</code></strong>  ：可以理解为一个队列，生产者和消费者面向的都是一个  <code>topic</code>；</p>
<p>6）<strong><code>Partition</code></strong>：为了实现扩展性，一个非常大的 <code>topic</code> 可以分布到多个 <code>broker</code>（即服务器）上，一个 <code>topic</code> 可以分为多个  <code>partition</code>，每个 <code>partition</code> 是一个有序的队列；</p>
<p>7）<strong><code>Replica</code></strong>：副本，为保证集群中的某个节点发生故障时，该节点上的 <code>partition</code> 数据不丢失，且 <code>kafka</code> 仍然能够继续工作，<code>kafka</code> 提供了副本机制，一个 <code>topic</code> 的每个分区都有若干个副本， 一个 <code>leader</code> 和若干个 <code>follower</code>。</p>
<p>8）<strong><code>leader</code></strong>：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 <code>leader</code>。</p>
<p>9）<strong><code>follower</code></strong>：每个分区多个副本中的“从”，实时从 <code>leader</code> 中同步数据，保持和 <code>leader</code> 数据的同步。<code>leader</code> 发生故障时，某个  follower 会成为新的  <code>follower</code>。</p>
<h1>第  2 章    Kafka 快速入门</h1>
<h2 id="2-1-安装部署">2.1 安装部署</h2>
<p><a href="https://kengkengya.github.io/dajiangdahe/2022/01/03/zookeeper_kafka_kafka-Manager%E5%8D%95%E6%9C%BA%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/">Zookeeper_kafka_kafka-Manager单机伪集群环境安装</a></p>
<h2 id="2-2-Kafka-命令行操作">2.2 Kafka 命令行操作</h2>
<ol>
<li>
<p>查看当前服务器里所有的<code>topics</code>:</p>
<figure class="highlight shell"><figcaption><span>l</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">/opt/kafka_2.13-2.8.1 # bin/kafka-topics.sh   --zookeeper 10.121.17.138:2181 --list<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>创建<code>tpoic</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">/opt/kafka_2.13-2.8.1 # bin/kafka-topics.sh --create  --zookeeper 10.121.17.138:2181 --topic first --partitions 2 --replication-factor 2<br>Created topic first.<br></code></pre></td></tr></table></figure>
</li>
</ol>
<p>​		选项说明：<br>
​				<code>	--topic</code>  定义 <code>topic</code> 名</p>
<p>​			<code>--replication-factor</code>    定义副本数</p>
<p><code>			--partitions </code>   定义分区数</p>
<ol start="3">
<li>
<p>删除<code>topic</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">/opt/kafka_2.13-2.8.1 # bin/kafka-topics.sh --delete  --zookeeper 10.121.17.138:2181 --topic first<br>Topic first is marked for deletion.<br>Note: This will have no impact if delete.topic.enable is not set to true.<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>查看<code>topic</code>详细信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">/opt/kafka_2.13-2.8.1 # bin/kafka-topics.sh --describe  --zookeeper 10.121.17.138:2181 --topic first<br><br>Topic: first	TopicId: h7I5zqd-R7Sj3hd-P7q1gQ	PartitionCount: 2	ReplicationFactor: 2	Configs:<br>	Topic: first	Partition: 0	Leader: 1	Replicas: 0,1	Isr: 1,0<br>	Topic: first	Partition: 1	Leader: 2	Replicas: 1,2	Isr: 2,1<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>发送消息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">bin/kafka-console-producer.sh --broker-list 10.121.17.138:9092 --topic first<br></code></pre></td></tr></table></figure>
</li>
<li>
<p>消费消息（必须先开启消息，再启动生产者）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sh">bin/kafka-console-consumer.sh  --zookeeper 10.121.17.138:2181 --topic first --from-beginning<br></code></pre></td></tr></table></figure>
<p><code>--from-beginning</code>：会把主题中以往所有的数据都读取出来</p>
</li>
<li>
<p>修改分区数</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">bin/kafka-topics.sh   --zookeeper 10.121.17.138:2181 --alter --topic first --partitions 6<br></code></pre></td></tr></table></figure>
</li>
</ol>
<h1>第  3 章    Kafka 架构深入</h1>
<h2 id="3-1-Kafka-工作流程及文件存储机制">3.1 Kafka 工作流程及文件存储机制</h2>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220105154350679.png" class="" title="image-20220105154350679">
<p><code>Kafka</code> 中消息是以  <code>topic</code> 进行分类的，生产者生产消息，消费者消费消息，都是面向  <code>topic</code> 的。</p>
<p><code>topic</code> 是逻辑上的概念，而 <code>partition</code> 是物理上的概念，<strong>每个 <code>partition</code> 对应于一个 <code>log</code> 文 件，该 <code>log</code> 文件中存储的就是 <code>producer</code> 生产的数据</strong>。<code>Producer</code> 生产的数据会被不断追加到该 log 文件末端，且每条数据都有自己的 <code>offset</code>。消费者组中的每个消费者，都会实时记录自己 消费到了哪个 <code>offset</code>，以便出错恢复时，从上次的位置继续消费。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220105155713384.png" class="" title="image-20220105155713384">
<p>由于生产者生产的消息会不断追加到 <code>log</code> 文件末尾，为防止 <code>log</code> 文件过大导致数据定位 效率低下，<strong>Kafka 采取了分片和索引机制</strong>，将每个 <code>partition</code> 分为多个 <code>segment</code>。每个 segment 对应两个文件——“<code>.index</code>”文件和“<code>.log</code>”文件。这些文件位于一个文件夹下，该文件夹的命名 规则为：<code>topic</code> 名称+分区序号。例如，first 这个 topic 有三个分区，则其对应的文件夹为<code> first- 0,first-1,first-2</code>。</p>
<figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-number">00000000000000000000</span>.<span class="hljs-built_in">index</span><br><span class="hljs-number">00000000000000000000</span>.<span class="hljs-built_in">log</span><br><span class="hljs-number">00000000000000170410</span>.<span class="hljs-built_in">index</span><br><span class="hljs-number">00000000000000170410</span>.<span class="hljs-built_in">log</span><br><span class="hljs-number">00000000000000239430</span>.<span class="hljs-built_in">index</span><br><span class="hljs-number">00000000000000239430</span>.<span class="hljs-built_in">log</span><br></code></pre></td></tr></table></figure>
<p><code>index</code> 和  <code>log</code> 文件以当前  <code>segment</code> 的第一条消息的  <code>offset</code> 命名。下图为  <code>index</code> 文件和  <code>log</code> 文件的结构示意图。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220105160059914.png" class="" title="image-20220105160059914">
<p>首先在<code>index</code>文件根据二分查找法查找索引（每一个offset都是一样大），找到<code>offset=3</code>的起始值。然后今后<code>log</code>文件进行查找。<code>**.index</code>文件存储大量的索引信息，<code>.log</code>文件存储大量的数据**，索引文件中的元数据指向对应数据文件中 <code>message</code> 的物理偏移地址。</p>
<h3 id="3-1-1-复制原理和同步方式">3.1.1 复制原理和同步方式</h3>
<p><code>Kafka</code>中<code>topic</code>的每个<code>partition</code>有一个预写式的日志文件，虽然<code>partition</code>可以继续细分为若干个<code>segment</code>文件，但是对于上层应用来说可以将<code>partition</code>看成最小的存储单元（一个有多个<code>segment</code>文件拼接的“巨型”文件），每个<code>partition</code>都由一些列有序的、不可变的消息组成，这些消息被连续的追加到<code>partition</code>中。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png.png" class="" title="这里写图片描述">
<p>上图中有两个新名词：<code>HW</code>和<code>LEO</code>。这里先介绍下<code>LEO</code>，<code>LogEndOffset``的缩写，表示每个</code>partition<code>的</code>log<code>最后一条</code>Message<code>的位置。</code>HW<code>HighWatermark</code>的缩写，是指<code>consumer</code>能够看到的此<code>partition</code>的位置，这个涉及到多副本的概念，这里先提及一下，下节再详表。</p>
<p>言归正传，为了提高消息的可靠性，<code>Kafka</code>每个<code>topic</code>的<code>partition</code>有N个副本（<code>replicas</code>），其中N(大于等于1)是<code>topic</code>的复制因子（<code>replica fator</code>）的个数。<code>Kafka</code>通过多副本机制实现故障自动转移，当Kafka<code>集群</code>中一个<code>broker</code>失效情况下仍然保证服务可用。在<code>Kafka</code>中发生复制时确保<code>partition</code>的日志能有序地写到其他节点上，N个<code>replicas</code>中，其中一个<code>replica</code>为<code>leader</code>，其他都为<code>follower</code>, <code>leader</code>处理<code>partition</code>的所有读写请求，与此同时，<code>follower</code>会被动定期地去复制<code>leader</code>上的数据。</p>
<p>如下图所示，<code>Kafka</code>集群中有4个<code>broker</code>, 某<code>topic</code>有3个<code>partition</code>,且复制因子即副本个数也为3：</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png-20220105164106125.png" class="" title="这里写图片描述">
<p><code>Kafka</code>提供了数据复制算法保证，如果<code>leader</code>发生故障或挂掉，一个新<code>leader</code>被选举并被接受客户端的消息成功写入。<code>Kafka</code>确保从同步副本列表中选举一个副本为<code>leader</code>，或者说<code>follower</code>追赶<code>leader</code>数据。<code>leader</code>负责维护和跟踪<code>ISR</code>(<code>In-Sync Replicas</code>的缩写，表示副本同步队列，具体可参考下节)中所有<code>follower</code>滞后的状态。当<code>producer</code>发送一条消息到<code>broker</code>后，<code>leader</code>写入消息并复制到所有<code>follower</code>。消息提交之后才被成功复制到所有的同步副本。消息复制延迟受最慢的<code>follower</code>限制，重要的是快速检测慢副本，如果<code>follower</code>“落后”太多或者失效，<code>leader</code>将会把它从<code>ISR</code>中删除。</p>
<p>另外每个<code>replica</code>都有<code>HW</code>,<code>leader</code>和<code>follower</code>各自负责更新自己的<code>HW</code>的状态。对于<code>leader</code>新写入的消息，<code>consumer</code>不能立刻消费，<code>leader</code>会等待该消息被所有ISR中的<code>replicas</code>同步后更新<code>HW</code>，此时消息才能被<code>consumer</code>消费。这样就保证了如果<code>leader</code>所在的<code>broker</code>失效，该消息仍然可以从新选举的<code>leader</code>中获取。对于来自内部<code>broker</code>的读取请求，没有<code>HW</code>的限制。</p>
<p>下图详细的说明了当<code>producer</code>生产消息至<code>broker</code>后，ISR以及HW和LEO的流转过程：</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/format,png-20220105164408305.png" class="" title="这里写图片描述">
<p>由此可见，<code>Kafka</code>的复制机制既不是完全的同步复制，也不是单纯的异步复制。事实上，同步复制要求所有能工作的<code>follower</code>都复制完，这条消息才会被<code>commit</code>，这种复制方式极大的影响了吞吐率。而异步复制方式下，<code>follower</code>异步的从<code>leader</code>复制数据，数据只要被<code>leader</code>写入<code>log</code>就被认为已经<code>commit</code>，这种情况下如果<code>follower</code>都还没有复制完，落后于<code>leader</code>时，突然<code>leader</code>宕机，则会丢失数据。而<code>Kafka</code>的这种使用<code>ISR</code>的方式则很好的均衡了确保数据不丢失以及吞吐率。</p>
<p><code>Kafka</code>的<code>ISR</code>的管理最终都会反馈到<code>Zookeeper</code>节点上。具体位置为：<code>/brokers/topics/[topic]/partitions/[partition]/state</code>。目前有两个地方会对这个<code>Zookeeper</code>的节点进行维护：</p>
<ul>
<li>
<p><code>Controller</code>来维护：<code>Kafka</code>集群中的其中一个<code>Broker</code>会被选举为<code>Controller</code>，主要负责<code>Partition</code>管理和副本状态管理，也会执行类似于重分配<code>partition</code>之类的管理任务。在符合某些特定条件下，<code>Controller</code>下的<code>LeaderSelector</code>会选举新的<code>leader</code>，<code>ISR</code>和新的<code>leader_epoch</code>及<code>controller_epoch</code>写入<code>Zookeeper</code>的相关节点中。同时发起<code>LeaderAndIsrRequest</code>通知所有的<code>replicas</code>。</p>
</li>
<li>
<p><code>leader</code>来维护：<code>leader</code>有单独的线程定期检测<code>ISR</code>中<code>follower</code>是否脱离<code>ISR</code>, 如果发现<code>ISR</code>变化，则会将新的<code>ISR</code>的信息返回到<code>Zookeeper</code>的相关节点中。</p>
</li>
</ul>
<h2 id="3-2-Kafka-生产者">3.2 Kafka 生产者</h2>
<h3 id="3-2-1-分区策略">3.2.1  分区策略</h3>
<p>1）分区的原因</p>
<p>​	（1）<strong>方便在集群中扩展</strong>，每个 <code>Partition</code> 可以通过调整以适应它所在的机器，而一个  <code>topic</code>又可以有多个 <code>Partition</code> 组成，因此整个集群就可以适应任意大小的数据了；</p>
<p>​	（2）<strong>可以提高并发</strong>，因为可以以 <code>Partition</code> 为单位读写了。</p>
<p>2）分区的原则</p>
<p>​	我们需要将 <code>producer</code> 发送的数据封装成一个 <code>ProducerRecord</code> 对象。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220105160759755-1370080.png" class="" title="image-20220105160759755">
<p>（1）指明   <code>partition</code>  的情况下，直接将指明的值直接作为   <code>partiton</code>  值；（权重）</p>
<p>（2）没有指明   <code>partition</code>  值但有   <code>key</code>  的情况下，将   <code>key</code>  的   <code>hash</code>  值与   <code>topic</code>  的   <code>partition</code> 数进行取余得到   partition  值；（hash）</p>
<p>（3）既没有 <code>partition</code>  值又没有 key  值的情况下，第一次调用时随机生成一个整数（后 面每次调用在这个整数上自增），将这个值与 <code>topic</code>  可用的 <code>partition</code>  总数取余得到 <code>partition</code> 值，也就是常说的 <code>round-robin</code>  算法。(轮询)</p>
<h3 id="3-2-2-数据可靠性保证">3.2.2  数据可靠性保证</h3>
<p>为保证 <code>producer</code> 发送的数据，能可靠的发送到指定的 <code>topic</code>，<code>topic</code> 的每个 <code>partition</code> 收到 <code>producer</code> 发送的数据后，都需要向 <code>producer</code> 发送 <code>ack</code>（<code>acknowledgement</code> 确认收到），如果 <code>producer</code> 收到 <code>ack</code>，就会进行下一轮的发送，否则重新发送数据。</p>
<img src="/dajiangdahe/2022/01/04/kafka%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/image-20220105161526377.png" class="" title="image-20220105161526377">
<p>1）副本数据同步策略</p>
<table>
<thead>
<tr>
<th>方案</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>半数以上完成同步，就发 送  <code>ack</code></td>
<td>延迟低</td>
<td>选举新的 <code>leader</code> 时，容忍 n 台 节点的故障，需要 <code>2n+1</code> 个副 本</td>
</tr>
<tr>
<td>全部完成同步，才发送 <code>ack</code></td>
<td>选举新的 <code>leader</code> 时，容忍 n 台 节点的故障，需要 n+1 个副 本</td>
<td>延迟高</td>
</tr>
</tbody>
</table>
<p><code>Kafka</code> 选择了第二种方案，原因如下：</p>
<ol>
<li>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1个副本，而 <code>Kafka</code> 的每个分区都有大量的数据，第一种方案会造成大量数据的冗余。</li>
<li>虽然第二种方案的网络延迟会比较高，但网络延迟对  <code>Kafka</code> 的影响较小。</li>
</ol>
<blockquote>
<ul>
<li>半数以上方案的缺点解释：宕机的N个机器，它们可能是同步好数据的那部分，也可能是没有同步好的那部分。如果坏掉的是同步好的那部分，那我们只需要N+1个副本(多出来的这个副本是仅仅或者说专门用来备份的节点机器，懂我意思吧)，如果坏掉的不是同步好的那部分，本身没有同步的数据，而且还缺一份备份，所以需要2N+1</li>
<li>全部同步才发送<code>ack</code>的方案：因为是所有的<code>follower</code>都同步好了，参照上面的解释，我们就仅仅需要N+1个副本就好。</li>
</ul>
</blockquote>
<p>2）ISR</p>
<p>采用第二种方案之后，设想以下情景：<code>leader</code> 收到数据，所有 <code>follower</code> 都开始同步数据， 但有一个 <code>follower</code>，因为某种故障，迟迟不能与 <code>leader</code> 进行同步，那 <code>leader</code> 就要一直等下去， 直到它完成同步，才能发送 <code>ack</code>。这个问题怎么解决呢？</p>
<p><code>Leader</code> 维护了一个动态的 <code>in-sync replica set (ISR)</code>，意为和 <code>leader</code> 保持同步的 <code>follower</code> 集 合。当 <code>ISR</code> 中的 <code>follower</code> 完成数据的同步之后，<code>leader</code> 就会给 <code>follower</code> 发送 <code>ack</code>。如果 <code>follower</code> 长时间未 向 <code>leader</code> 同 步 数 据 ， 则 该 <code>follower</code> 将 被 踢 出<code> ISR</code> ， 该 时 间 阈 值 由<code>replica.lag.time.max.ms</code> 参数设定。<code>Leader</code> 发生故障之后，就会从  <code>ISR</code> 中选举新的  <code>leader</code>。</p>
<p>默认情况下<code>Kafka</code>的<code>replica</code>数量为1，即每个<code>partition</code>都有一个唯一的<code>leader</code>，为了确保消息的可靠性，通常应用中将其值(由<code>broker</code>的参数<code>offsets.topic.replication.factor</code>指定)大小设置为大于1，比如3。 所有的副本（<code>replicas</code>）统称为<code>Assigned Replicas</code>，即<code>AR</code>。<code>ISR</code>是<code>AR</code>中的一个子集，由<code>leader</code>维护<code>ISR</code>列表，<code>follower</code>从<code>leader</code>同步数据有一些延迟（包括延迟时间<code>replica.lag.time.max.ms</code>和延迟条数<code>replica.lag.max.messages</code>两个维度, 当前最新的版本<code>0.10.x</code>中只支持<code>replica.lag.time.max.ms</code>这个维度），任意一个超过阈值都会把<code>follower</code>剔除出<code>ISR</code>, 存入<code>OSR</code>（<code>Outof-Sync Replicas</code>）列表，新加入的<code>follower</code>也会先存放在<code>OSR</code>中。<code>AR=ISR+OSR</code>。</p>
<p><code>Kafka 0.9.0.0</code>版本后移除了<code>replica.lag.max.messages</code>参数，只保留了<code>replica.lag.time.max.ms</code>作为ISR中副本管理的参数。为什么这样做呢？</p>
<p><code>replica.lag.max.messages</code>表示当前某个副本落后<code>leader</code>的消息数量超过了这个参数的值，那么<code>leader</code>就会把<code>follower</code>从<code>ISR</code>中删除。假设设置<code>replica.lag.max.messages</code>=4，那么如果<code>producer</code>一次传送至<code>broker</code>的消息数量都小于4条时，因为在<code>leader</code>接受到<code>producer</code>发送的消息之后而<code>follower</code>副本开始拉取这些消息之前，<code>follower</code>落后<code>leader</code>的消息数不会超过4条消息，故此没有<code>follower</code>移出<code>ISR</code>，所以这时候<code>replica.lag.max.message</code>的设置似乎是合理的。但是<code>producer</code>发起瞬时高峰流量，<code>producer</code>一次发送的消息超过4条时，也就是超过<code>replica.lag.max.messages</code>，此时follower都会被认为是与<code>leader</code>副本不同步了，从而被踢出了<code>ISR</code>。但实际上这些<code>follower</code>都是存活状态的且没有性能问题。那么在之后追上<code>leader</code>,并被重新加入了<code>ISR</code>。于是就会出现它们不断地剔出<code>ISR</code>然后重新回归<code>ISR</code>，这无疑增加了无谓的性能损耗。而且这个参数是<code>broker</code>全局的。设置太大了，影响真正“落后”<code>follower</code>的移除；设置的太小了，导致<code>follower</code>的频繁进出。无法给定一个合适的<code>replica.lag.max.messages</code>的值，故此，新版本的<code>Kafka</code>移除了这个参数。</p>
<blockquote>
<p><code>ISR</code>包括<code>leader</code>和<code>follow</code></p>
</blockquote>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/dajiangdahe/categories/kafka/">kafka</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/dajiangdahe/tags/kafka/">kafka</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/dajiangdahe/2022/01/05/%E3%80%90%E6%94%BF%E6%B2%BB%E3%80%91%E5%8A%A8%E7%89%A9%E5%86%9C%E5%9C%BA/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">动物农场</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/dajiangdahe/2022/01/03/zookeeper_kafka_kafka-Manager%E5%8D%95%E6%9C%BA%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/">
                        <span class="hidden-mobile">Zookeeper_kafka_kafka-Manager单机集群环境安装</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
    
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  
  <!-- 备案信息 -->
  <div class="beian">
    <span>
      <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
        京ICP证123456号
      </a>
    </span>
    
      
        <span>
          <a
            href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=12345678"
            rel="nofollow noopener"
            class="beian-police"
            target="_blank"
          >
            
              <span style="visibility: hidden; width: 0">|</span>
              <img src="/dajiangdahe/img/police_beian.png" alt="police-icon"/>
            
            <span>京公网安备12345678号</span>
          </a>
        </span>
      
    
  </div>


  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/dajiangdahe/js/events.js" ></script>
<script  src="/dajiangdahe/js/plugins.js" ></script>

<!-- Plugins -->




  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/dajiangdahe/js/local-search.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>












  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/dajiangdahe/js/boot.js" ></script>


</body>
</html>
